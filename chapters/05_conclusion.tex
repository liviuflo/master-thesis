\chapter{Conclusion}
\label{ch:conclusion}

This work addressed odometry, a fundamental topic of mobile robotics, with emphasis on the area of perception, and was driven by its applicability to an industrial product, the SDX-Compact manufactured by Sodex Innovations GmbH. Range information from a 360-degree LiDAR sensor is fused with localization and orientation measurements provided by an INS, to increase robustness to GPS perturbations and enable 3D mapping quality beyond the accuracy of RTK-corrected readings.

We provided a review of the current state of research around this problem and its many facets. This was followed by a presentation of the hardware and data that we operate on, and a detailed explanation of the experiments conducted around each component of our final solution. Our contribution is an original displacement estimation method which relies on a two-step scan alignment process (robust ICP and Generalized ICP) and a factor graph structure, where registration results are combined with absolute GPS readings. To enforce point cloud registration constraints, we add ``skip connections'' between non-consecutive poses, based on the ICP-estimated displacement. GPS readings introduce unary factors which prevent trajectory drift and remove the need for a loop closure mechanism. The results show that our method is able to handle LiDAR scans captured at irregular time intervals, noisy GPS, or gaps in the sequence of GPS measurements.

We test our solution in multiple scenarios, with varying parameter configurations, and evaluate odometry on the KITTI dataset~\cite{geiger2013vision} and on a custom dataset collected with the SDX-Compact. Unlike other odometry or SLAM approaches, we are also interested in the mapping quality --- the complete point cloud captured along the trajectory --- so we evaluate the output 3D map against GPS-only results. We obtain smoother and more fine-detailed maps, thanks to the registration constraints.

Guided by the research questions laid out in the initial stage of the project, the conducted work included multiple experiments which allow us to provide concrete and detailed answers.
\begin{compactenum}
    \item \textit{What metrics exist for measuring the accuracy of point cloud registration?}

    Point cloud registration can be evaluated in several ways, depending on the use case and the desired result. If ground truth displacement is available (\eg from an external sensor system or by designing a scene with custom objects which can be identified and localized precisely), it can be compared to the transformation computed by the registration algorithm.
    In most scenarios, however, registration accuracy is approximated as an error function between the two scans, after they have been transformed to a common reference frame. The metrics are a combination of distance measurements between 3D elements identified in both point clouds (correspondences), such as points, planes, edges, etc., aiming to quantify the geometric consistency of the combined point cloud. Sensor noise and outliers introduce particular challenges, if a generic metric is sought. In our case, registration accuracy is indicated by the RMSE value obtained after applying GICP, which is a point-to-point metric. Alternative metrics can be formulated using covariance estimation for local 3D neighborhoods~\cite{adolfsson2021coral} or the transformation resulting from the registration process~\cite{censi2007accurate}.

    \item \textit{Can methods that use only visual information achieve higher quality point cloud registration (3D mapping) than merging based on RTK?}

    Registering point clouds using the intrinsic visual information generally results in higher quality 3D maps --- we have obtained maps that have lower entropy and smoother surfaces. However, this is subject to having an accurate motion estimation mechanism, in order to perform scan de-skewing and ensure that the range information from the LiDAR sensor is representative of the real world. Because this depends on the velocity of the vehicle and the features present in the environment, it could be argued that the LiDAR output alone is not sufficient for accurate registration.

    \item \textit{To what extent is LiDAR-based odometry an alternative to GNSS localization?}

    We have designed, implemented and evaluated a LiDAR-based odometry method which achieves, on average, less than 1m of drift in the horizontal plane, when travelling for 100m (according to the results in Table~\ref{tab:odom-kitti}). Unsurprisingly, this highlights a general limitation of dead-reckoning methods: small errors that accumulate in time, resulting in poor localization. Therefore, employing LiDAR-based odometry as an alternative to GNSS localization depends on the use-case. If it is used to approximate relatively small local displacements (\eg to increase the frequency of state estimation beyond the frequency of the GPS receiver) or if the the GNSS readings have large uncertainty, LiDAR odometry proves a reliable solution. Another limitation is the nature of the environment, as point cloud registration cannot be accurately performed in degenerate or featureless scenes.

\end{compactenum}

% discuss general conclusions about the data used and the problems encountered
% discuss research questions

\section{Future Work}

There are several directions worth investigating for improving the current approach, if more time and human resource is available. One particular issue that surfaced during the evaluation stage was the high drift in the vertical axis. Although it is not unexpected, because we did not employ any particular methods for preventing this (unlike \mbox{LeGO-LOAM \cite{legoloam2018}}, for example), a thorough investigation is required. It could be hypothesized that this is caused by the GICP registration overfitting the alignment between ground regions of the point clouds, in the presence of noisy outliers, or some inaccuracy in the scan de-skewing process.

Performing motion compensation without relying on the poses provided by the INS is another potential improvement which would make our solution applicable to a wider range of systems. This is a vast research problem that could be tackled by extracting the raw IMU measurements from the available sensor, or by developing a dedicated component for correcting the incoming LiDAR scans.

Another limitation of our method is that it does not take into account the beam intensity values provided by the sensor or the RGB camera output, which could prove very useful for registering scans in areas with few useful 3D features. There are methods for performing ICP on point clouds with associated color information \cite{park2017colored}, and LiDAR odometry has benefited from intensity data in the past \cite{pfreundschuh2024coin}.

Although performance was not one of our immediate constraints, we believe that the computational cost of our approach could be reduced drastically if the implementation were done in C++ instead of Python, to meet the requirements of real-time systems. Creating a ROS 2 interface that enables arbitrary robotic setups to forward LiDAR and GPS data to our solution is another possible improvement on the software side.

% dynamic correspondence filtering

% discuss project management?